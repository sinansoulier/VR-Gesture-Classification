{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vr_recognition.data import Data\n",
    "from vr_recognition.hardware import Hardware\n",
    "from vr_recognition.model_utils import ModelUtils\n",
    "from vr_recognition.vr_gesture_recognizer import VRGestureRecognizer\n",
    "from vr_recognition.hardware import Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 VRAI HORIZONTAL\n",
      "1 FAUX HORIZONTAL\n",
      "2 FAUX VERTICAL\n",
      "3 VRAI VERTICAL\n",
      "4 NON VERTICAL\n",
      "5 NON HORIZONTAL\n",
      "6 OUI VERTICAL\n",
      "7 OUI HORIZONTAL\n"
     ]
    }
   ],
   "source": [
    "base_dir: str = os.path.join(os.getcwd(), 'simulated_data_v2')\n",
    "\n",
    "tuple_data: tuple[list[pd.DataFrame], np.ndarray, np.ndarray] = Data.load_data(base_dir)\n",
    "\n",
    "# Unpack data\n",
    "pd_data: list[pd.DataFrame] = tuple_data[0]\n",
    "labels: np.ndarray = tuple_data[1]\n",
    "classes: np.ndarray = tuple_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: np.ndarray = Data.convert_to_numpy(pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Class defining the encoder architecture of an encoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int = 2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim * 2, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim * 2, hidden_dim * 2, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "        # Dropout layer(s)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model. This method is called when performing inference, training or evaluation.\n",
    "        Params:\n",
    "            x (torch.Tensor): Input data\n",
    "        Returns:\n",
    "            torch.Tensor: Output data.\n",
    "                          The shape of the output tensor depends on the number of classes that characterizes the model.\n",
    "        \"\"\"\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        encoded = self.relu(self.conv4(x))\n",
    "\n",
    "        encoded = self.dropout(encoded)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trim(nn.Module):\n",
    "    \"\"\"\n",
    "    Class that defines a trimming layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, size1: int, size2: int):\n",
    "        super(Trim, self).__init__()\n",
    "        self.size1 = size1\n",
    "        self.size2 = size2\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the layer. This method is called when performing inference, training or evaluation.\n",
    "        Params:\n",
    "            x (torch.Tensor): Input data\n",
    "        Returns:\n",
    "            torch.Tensor: Trimmed data.\n",
    "        \"\"\"\n",
    "        return x[:, :, :self.size1, :self.size2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Class defining the decoder architecture of the VAE.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int = 2, img_shape: tuple[int, int] = (72, 114)):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim * 2, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv4 = nn.ConvTranspose2d(hidden_dim, 1, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "        # Trimming\n",
    "        self.trim = Trim(img_shape[0], img_shape[1])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder.\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Decoded tensor representing the reconstructed data.\n",
    "        \"\"\"\n",
    "        x = self.relu(self.deconv1(x))\n",
    "        x = self.relu(self.deconv2(x))\n",
    "        x = self.relu(self.deconv3(x))\n",
    "        decoded = self.relu(self.deconv4(x))\n",
    "\n",
    "        decoded = self.trim(decoded)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = Hardware.device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Class defining the GAN architecture.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
