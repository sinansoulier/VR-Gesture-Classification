{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation - Variational Auto Encoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OUI\n",
      "1 NON\n",
      "2 VRAI\n",
      "3 FAUX\n"
     ]
    }
   ],
   "source": [
    "base_dir: str = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "tuple_data: tuple[list[pd.DataFrame], np.ndarray, np.ndarray] = Data.load_data(base_dir)\n",
    "\n",
    "# Unpack data\n",
    "pd_data: list[pd.DataFrame] = tuple_data[0]\n",
    "labels: np.ndarray = tuple_data[1]\n",
    "classes: np.ndarray = tuple_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: np.ndarray = Data.convert_to_numpy(pd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, hidden_dim, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, hidden_dim * 2, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(hidden_dim * 2, hidden_dim * 2, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dropout layer(s)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        encoded = self.relu(self.conv4(x))\n",
    "\n",
    "        encoded = self.dropout(encoded)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trim(nn.Module):\n",
    "    def __init__(self, size1, size2):\n",
    "        super(Trim, self).__init__()\n",
    "        self.size1 = size1\n",
    "        self.size2 = size2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x[:, :, :self.size1, :self.size2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 2, img_shape: tuple = (72, 114)):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim * 2, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_dim, hidden_dim, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv4 = nn.ConvTranspose2d(hidden_dim, 1, kernel_size=3, stride=2, padding=1, output_padding=0)\n",
    "\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Trimming\n",
    "        self.trim = Trim(img_shape[0], img_shape[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.deconv1(x))\n",
    "        x = self.relu(self.deconv2(x))\n",
    "        x = self.relu(self.deconv3(x))\n",
    "        decoded = self.relu(self.deconv4(x))\n",
    "\n",
    "        decoded = self.trim(decoded)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>**Log-variance:**</u><br><br>\n",
    "Instead of learning the variance $\\sigma^2$, we here learn the log-variance $\\log(\\sigma^2)$ because it can take any real number, while the variance can only take positive values. We can then exponentiate the log-variance to get the variance. Here is how we can do this:<br>\n",
    "\n",
    "$$\\log(\\sigma^2) = 2 * \\log(\\sigma)$$\n",
    "$$\\log(\\sigma^2) / 2 = \\log(\\sigma)$$\n",
    "$$e^{\\log(\\sigma^2) / 2} = \\sigma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 17 batches, validating on 3 batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a426dc27cd74d23afde5b86bf78dde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1000/1000], loss: 345.71, val_loss: 1432.10                          \r"
     ]
    }
   ],
   "source": [
    "DEVICE = 'mps'\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 128, latent_dim: int = 2, input_shape: tuple = (72, 114)):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(hidden_dim=hidden_dim)\n",
    "        self.decoder = Decoder(hidden_dim=hidden_dim)\n",
    "\n",
    "        self.nb_features = hidden_dim * 2\n",
    "        self.intermediate_shape = (math.ceil(input_shape[0] / (2 ** 4)), math.ceil(input_shape[1] / (2 ** 4)))\n",
    "\n",
    "        intermediary_dim = self.nb_features * self.intermediate_shape[0] * self.intermediate_shape[1]\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(intermediary_dim, hidden_dim)\n",
    "        self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, intermediary_dim)\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        sigma = torch.exp(logvar * 0.5).to(DEVICE)\n",
    "        epsilon = torch.randn_like(sigma).to(DEVICE)\n",
    "\n",
    "        return mu + epsilon * sigma\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        flattened_encoded = encoded.view(x.size(0), -1)\n",
    "\n",
    "        hidden = self.fc1(flattened_encoded)\n",
    "\n",
    "        mu, logvar = self.mu_layer(hidden), self.logvar_layer(hidden)\n",
    "\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        z = self.fc2(z)\n",
    "        reshaped_z = z.view(x.size(0),\n",
    "                            self.nb_features,\n",
    "                            self.intermediate_shape[0],\n",
    "                            self.intermediate_shape[1])\n",
    "\n",
    "        decoded = self.decoder(reshaped_z)\n",
    "\n",
    "        return decoded, mu, logvar\n",
    "\n",
    "    def loss_function(self, x, x_hat, mu, logvar):\n",
    "        reconstruction_loss = nn.MSELoss()(x_hat, x)\n",
    "        kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return reconstruction_loss + kld_loss\n",
    "    \n",
    "    def fit(self, X_train, X_val, epochs: int = 10, learning_rate: float = 1e-3, batch_size: int = 32):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        \n",
    "        n_train_batches = X_train.shape[0] // batch_size\n",
    "        n_val_batches = X_val.shape[0] // batch_size\n",
    "\n",
    "        print('Training on {} batches, validating on {} batches'.format(n_train_batches, n_val_batches))\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            mean_loss = 0\n",
    "            self.train()\n",
    "            for i, x in enumerate(Data.unlabeled_data_generator(X_train, batch_size=batch_size)):\n",
    "                x = x.to(DEVICE).unsqueeze(1)\n",
    "                x_hat, mu, logvar = self(x)\n",
    "                loss = self.loss_function(x, x_hat, mu, logvar)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                mean_loss += loss.item()\n",
    "            \n",
    "            mean_loss /= n_train_batches\n",
    "\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                mean_val_loss = 0\n",
    "                for i, x in enumerate(Data.unlabeled_data_generator(X_val, batch_size=batch_size)):\n",
    "                    x = x.to(DEVICE).unsqueeze(1)\n",
    "                    x_hat, mu, logvar = self(x)\n",
    "                    val_loss = self.loss_function(x, x_hat, mu, logvar)\n",
    "\n",
    "                    mean_val_loss += val_loss.item()\n",
    "\n",
    "                mean_val_loss /= n_val_batches\n",
    "                print('epoch [{}/{}], loss: {:.2f}, val_loss: {:.2f}                         '.format(epoch+1, epochs, mean_loss, mean_val_loss), end='\\r')\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.mps.manual_seed(seed)\n",
    "\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.15, random_state=seed)\n",
    "\n",
    "vae = VariationalAutoEncoder(hidden_dim=32, latent_dim=16).to(DEVICE)\n",
    "vae.fit(X_train, X_val, epochs=1000, learning_rate=1e-3, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 344.11517333984375\n"
     ]
    }
   ],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    test_mean_loss = 0\n",
    "    n_test_batches = X_test.shape[0] // 4\n",
    "    for i, x in enumerate(Data.unlabeled_data_generator(X_test, batch_size=4)):\n",
    "        images = x.to(DEVICE).unsqueeze(1)\n",
    "        x_hat, z_mu, z_logvar = vae(images)\n",
    "        test_mean_loss = vae.loss_function(x_hat, images, z_mu, z_logvar)\n",
    "        test_mean_loss += test_mean_loss.item()\n",
    "        \n",
    "    test_mean_loss = test_mean_loss / n_test_batches\n",
    "    print(f\"Test loss: {test_mean_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
