{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VR - Motion recognition with simple gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Matplotlib\n",
    "* PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Generator, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base data directory\n",
    "base_dir: str = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Load data\n",
    "tuple_data: tuple[np.ndarray, np.ndarray, np.ndarray] = Data.load_data(base_dir)\n",
    "\n",
    "# Unpack data\n",
    "data: np.ndarray = tuple_data[0]\n",
    "labels: np.ndarray = tuple_data[1]\n",
    "classes: np.ndarray = tuple_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X: np.ndarray, y: np.ndarray, batch_size: int=32) -> Generator:\n",
    "    \"\"\"\n",
    "    Data generator for PyTorch.\n",
    "    Params:\n",
    "        X (np.ndarray): Data\n",
    "        y (np.ndarray): Labels\n",
    "        batch_size (int): Size of the batch, default to 32\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]: Tuple containing the data and the labels\n",
    "    \"\"\"\n",
    "    # Number of samples\n",
    "    n_samples: int = X.shape[0]\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices: np.ndarray = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Shuffle data\n",
    "    X: np.ndarray = X[indices]\n",
    "    y: np.ndarray = y[indices]\n",
    "    \n",
    "    # Iterate over the dataset\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        # Get batch data\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        X_batch = torch.from_numpy(X_batch)\n",
    "        y_batch = torch.from_numpy(y_batch)\n",
    "        \n",
    "        # Yield the batch\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device() -> str:\n",
    "    \"\"\"\n",
    "    Returns the device to use for training.\n",
    "    Returns:\n",
    "        device: str - Device to use for training\n",
    "    \"\"\"\n",
    "    # Define CPU as default device\n",
    "    device = \"cpu\"\n",
    "\n",
    "    # Use Cuda acceleration if available (Nvidia GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "    # Use Metal acceleration if available (MacOS)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps:0\"\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRGestureRecognizer(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes: int, learning_rate: float = 1e-3):\n",
    "        super(VRGestureRecognizer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*4*7, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.maxpool(self.relu(self.conv1(x)))\n",
    "        out = self.maxpool(self.relu(self.conv2(out)))\n",
    "        out = self.maxpool(self.relu(self.conv3(out)))\n",
    "        out = self.maxpool(self.relu(self.conv4(out)))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.softmax(self.fc3(out))\n",
    "        return out\n",
    "    \n",
    "    def fit(self, X, y, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            mean_loss = 0\n",
    "            mean_acc = 0\n",
    "\n",
    "            data_gen: Generator =  data_generator(X, y, batch_size=batch_size)\n",
    "            n_batches = 0\n",
    "            self.train()\n",
    "            for i, batch in enumerate(data_gen):\n",
    "                n_batches += 1\n",
    "                # Get batch data\n",
    "                X_batch, y_batch = batch\n",
    "                X_batch, y_batch = X_batch.to(device()).unsqueeze(1), y_batch.to(device())\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self(X_batch)\n",
    "                loss = self.loss_fn(outputs, y_batch.long())\n",
    "            \n",
    "                # Backward and optimize\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update epoch loss\n",
    "                mean_loss += loss.item()\n",
    "                # Update epoch accuracy\n",
    "                mean_acc += outputs.to('cpu').argmax(dim=1).eq(y_batch.to('cpu')).sum().item()\n",
    "\n",
    "                # Compute mean loss and accuracy for the current epoch\n",
    "            mean_loss /= n_batches\n",
    "            mean_acc = mean_acc / (n_batches * batch_size)\n",
    "        \n",
    "            # Print epoch results\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {loss.item():.2f} | Accuracy: {mean_acc:.2f}\")\n",
    "            if mean_acc > 0.9:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Loss: 1.50 | Accuracy: 0.28\n",
      "Epoch [2/50] | Loss: 1.14 | Accuracy: 0.30\n",
      "Epoch [3/50] | Loss: 1.54 | Accuracy: 0.30\n",
      "Epoch [4/50] | Loss: 1.64 | Accuracy: 0.30\n",
      "Epoch [5/50] | Loss: 1.64 | Accuracy: 0.30\n",
      "Epoch [6/50] | Loss: 1.34 | Accuracy: 0.30\n",
      "Epoch [7/50] | Loss: 1.44 | Accuracy: 0.30\n",
      "Epoch [8/50] | Loss: 1.14 | Accuracy: 0.30\n",
      "Epoch [9/50] | Loss: 1.44 | Accuracy: 0.30\n",
      "Epoch [10/50] | Loss: 1.44 | Accuracy: 0.30\n",
      "Epoch [11/50] | Loss: 1.24 | Accuracy: 0.30\n",
      "Epoch [12/50] | Loss: 1.64 | Accuracy: 0.30\n",
      "Epoch [13/50] | Loss: 1.49 | Accuracy: 0.32\n",
      "Epoch [14/50] | Loss: 1.44 | Accuracy: 0.30\n",
      "Epoch [15/50] | Loss: 1.28 | Accuracy: 0.30\n",
      "Epoch [16/50] | Loss: 1.24 | Accuracy: 0.32\n",
      "Epoch [17/50] | Loss: 1.27 | Accuracy: 0.36\n",
      "Epoch [18/50] | Loss: 1.23 | Accuracy: 0.50\n",
      "Epoch [19/50] | Loss: 1.13 | Accuracy: 0.56\n",
      "Epoch [20/50] | Loss: 1.03 | Accuracy: 0.56\n",
      "Epoch [21/50] | Loss: 1.06 | Accuracy: 0.56\n",
      "Epoch [22/50] | Loss: 0.99 | Accuracy: 0.74\n",
      "Epoch [23/50] | Loss: 0.93 | Accuracy: 0.78\n",
      "Epoch [24/50] | Loss: 0.87 | Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 50\n",
    "\n",
    "gesture_recognizer = VRGestureRecognizer(hidden_size=128, num_classes=classes.shape[0]).to(device(), dtype=torch.float32)\n",
    "optimizer = torch.optim.Adam(gesture_recognizer.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.15, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(EPOCHS):\n",
    "    mean_loss = 0\n",
    "    mean_acc = 0\n",
    "\n",
    "    data_gen =  data_generator(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "    n_batches = 0\n",
    "    gesture_recognizer.train()\n",
    "    for i, batch in enumerate(data_gen):\n",
    "        n_batches += 1\n",
    "        # Get batch data\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch, y_batch = X_batch.to(device()).unsqueeze(1), y_batch.to(device())\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = gesture_recognizer(X_batch)\n",
    "        loss = criterion(outputs, y_batch.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update epoch loss\n",
    "        mean_loss += loss.item()\n",
    "        # Update epoch accuracy\n",
    "        mean_acc += outputs.to('cpu').argmax(dim=1).eq(y_batch.to('cpu')).sum().item()\n",
    "\n",
    "    # Compute mean loss and accuracy for the current epoch\n",
    "    mean_loss /= n_batches\n",
    "    mean_acc = mean_acc / (n_batches * BATCH_SIZE)\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Loss: {loss.item():.2f} | Accuracy: {mean_acc:.2f}\")\n",
    "    if mean_acc > 0.9:\n",
    "        break\n",
    "# gesture_recognizer.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.93 | Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, y) -> None:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = torch.from_numpy(X).to(device()).unsqueeze(1)\n",
    "        y = torch.from_numpy(y).to(device())\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y.long())\n",
    "        acc = outputs.to('cpu').argmax(dim=1).eq(y.to('cpu')).sum().item() / X.shape[0]\n",
    "        print(f\"Loss: {loss.item():.2f} | Accuracy: {acc:.2f}\")\n",
    "\n",
    "evaluate(gesture_recognizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "def export_to_onnx(model, path: str) -> None:\n",
    "    model.eval()\n",
    "    X = torch.randn(BATCH_SIZE, 1, 71, 114, requires_grad=True)\n",
    "    torch.onnx.export(model.to('cpu'), X, path, export_params=True, opset_version=10, do_constant_folding=True, input_names=['input'], output_names=['output'], dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "\n",
    "export_to_onnx(gesture_recognizer, 'gesture_recognizer.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
