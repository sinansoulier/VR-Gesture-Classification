{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VR - Motion recognition with simple gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Matplotlib\n",
    "* PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LearningCurveDisplay, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import Data\n",
    "from utils.hardware import Hardware\n",
    "from utils.vr_gesture_recognizer import VRGestureRecognizer\n",
    "from utils.plot import Plot\n",
    "from utils.model_utils import ModelUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first begin by loading all the data from the csv files. We retrieve **all the raw data** into **a single numpy array**. We retrieve the **labels** into **a separate array**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base data directory\n",
    "base_dir: str = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Load data\n",
    "tuple_data: tuple[np.ndarray, np.ndarray, np.ndarray] = Data.load_data(base_dir)\n",
    "\n",
    "# Unpack data\n",
    "data: np.ndarray = tuple_data[0]\n",
    "labels: np.ndarray = tuple_data[1]\n",
    "classes: np.ndarray = tuple_data[2]\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and hyperparameters ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the **settings** and **hyperparameters** for the model. Here are the ones we will use for our use case:\n",
    "* Device: the device on which the model will be trained. We will use a GPU if available, otherwise we will use the CPU.\n",
    "* Batch size: the number of samples that will be propagated through the network at once.\n",
    "* Number of epochs: the number of times the entire dataset will be passed through the network.\n",
    "* Learning rate: the step size at each iteration while moving toward a minimum of a loss function.\n",
    "* Hidden size: the size of the hidden layer in the fully connected part of the network.\n",
    "* Number of labels: the number of labels in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = Hardware.device()\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LABELS = classes.shape[0]\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_recognizer = VRGestureRecognizer(hidden_size=HIDDEN_SIZE, num_classes=NUM_LABELS).to(Hardware.device(), dtype=torch.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "gesture_recognizer.compile(loss_fn)\n",
    "training_history = gesture_recognizer.fit(X_train, y_train, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE, learning_rate=LEARNING_RATE)\n",
    "\n",
    "gesture_recognizer.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate the model on the test set. We will use the accuracy and the loss of the model as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = gesture_recognizer.to(Hardware.device()).evaluate(X_test, y_test)\n",
    "print(f\"Loss: {test_loss.item():.2f} | Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make predictions on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gesture_recognizer.to(Hardware.device()).predict(X_test).cpu().numpy().astype(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_recognizer_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "Plot.plot_confusion_matrix(gesture_recognizer_confusion_matrix, fig_size=(6, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before exporting the model, we will first clean the model saving directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('models'):\n",
    "    for f in os.listdir('models'):\n",
    "        os.remove(os.path.join('models', f))\n",
    "else:\n",
    "    os.mkdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesture_recognizer.export_to_onnx(path='models/vr_gesture_recognizer.onnx', data_shape=data.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost - Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=128,\n",
    "    learning_rate=0.1,\n",
    "    objective='multi:softmax',\n",
    "    num_class=classes.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=20)\n",
    "scores = cross_val_score(xgb_classifier, X_train.reshape(X_train.shape[0], -1), y_train, cv=kFold, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross validation mean accuracy: {scores.mean() * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "y_pred = xgb_classifier.predict(X_test.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "Plot.plot_confusion_matrix(xgb_confusion_matrix, fig_size=(6, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.save_sklearn_model_to_onnx(\n",
    "    xgb_classifier,\n",
    "    path='models/xgb_gesture_recognizer.onnx',\n",
    "    data_shape=data.shape[1:],\n",
    "    is_xgboost=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=64,\n",
    "    class_weight='balanced',\n",
    "    random_state=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "scores = cross_val_score(rf_classifier, X_train.reshape(X_train.shape[0], -1), y_train, cv=kFold, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross validation mean accuracy: {scores.mean() * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    rf_classifier,\n",
    "    data.reshape(data.shape[0], -1),\n",
    "    labels,\n",
    "    cv= ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.01, 1.0, 5),\n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "y_pred = rf_classifier.predict(X_test.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "Plot.plot_confusion_matrix(rf_confusion_matrix, fig_size=(6, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.save_sklearn_model_to_onnx(rf_classifier, path='models/random_forest.onnx', data_shape=data.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=128,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "scores = cross_val_score(dt_classifier, X_train.reshape(X_train.shape[0], -1), y_train, cv=kFold, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross validation mean accuracy: {scores.mean() * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    dt_classifier,\n",
    "    data.reshape(data.shape[0], -1),\n",
    "    labels,\n",
    "    cv= ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.01, 1.0, 5),\n",
    "    ax=ax\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "y_pred = dt_classifier.predict(X_test.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "Plot.plot_confusion_matrix(dt_confusion_matrix, fig_size=(6, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelUtils.save_sklearn_model_to_onnx(dt_classifier, path='models/decision_tree.onnx', data_shape=data.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"--- {int((end_time - start_time) / 60)} minutes, {int((end_time - start_time) % 60)} seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
